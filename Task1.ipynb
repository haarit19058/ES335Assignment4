{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9841022,"sourceType":"datasetVersion","datasetId":6037054}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Relevant Libraries","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary\n!pip install watermark","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:38:18.389818Z","iopub.execute_input":"2024-11-13T18:38:18.390222Z","iopub.status.idle":"2024-11-13T18:38:42.877860Z","shell.execute_reply.started":"2024-11-13T18:38:18.390152Z","shell.execute_reply":"2024-11-13T18:38:42.876902Z"}},"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\nCollecting watermark\n  Downloading watermark-2.5.0-py2.py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: ipython>=6.0 in /opt/conda/lib/python3.10/site-packages (from watermark) (8.21.0)\nRequirement already satisfied: importlib-metadata>=1.4 in /opt/conda/lib/python3.10/site-packages (from watermark) (7.0.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from watermark) (70.0.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=1.4->watermark) (3.19.2)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (0.1.7)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (0.6.2)\nRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (5.14.3)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.0->watermark) (0.2.13)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.0->watermark) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.0->watermark) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.0->watermark) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.0->watermark) (1.16.0)\nDownloading watermark-2.5.0-py2.py3-none-any.whl (7.7 kB)\nInstalling collected packages: watermark\nSuccessfully installed watermark-2.5.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom io import BytesIO\nimport torch\nfrom torchsummary import summary\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nimport torchvision.models as models \nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import ConcatDataset\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:38:42.879936Z","iopub.execute_input":"2024-11-13T18:38:42.880264Z","iopub.status.idle":"2024-11-13T18:39:02.703291Z","shell.execute_reply.started":"2024-11-13T18:38:42.880230Z","shell.execute_reply":"2024-11-13T18:39:02.702503Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import warnings\n\n# Suppress all warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:02.704497Z","iopub.execute_input":"2024-11-13T18:39:02.705043Z","iopub.status.idle":"2024-11-13T18:39:02.709605Z","shell.execute_reply.started":"2024-11-13T18:39:02.705007Z","shell.execute_reply":"2024-11-13T18:39:02.708800Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from watermark import watermark\n\n# Printing versions of libraries used\n%load_ext watermark\n%watermark -v -p torch,torchvision,torchsummary,numpy,matplotlib,PIL","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:02.712071Z","iopub.execute_input":"2024-11-13T18:39:02.712463Z","iopub.status.idle":"2024-11-13T18:39:02.766050Z","shell.execute_reply.started":"2024-11-13T18:39:02.712420Z","shell.execute_reply":"2024-11-13T18:39:02.765214Z"}},"outputs":[{"name":"stdout","text":"Python implementation: CPython\nPython version       : 3.10.14\nIPython version      : 8.21.0\n\ntorch       : 2.4.0\ntorchvision : 0.19.0\ntorchsummary: 1.5.1\nnumpy       : 1.26.4\nmatplotlib  : 3.7.5\nPIL         : 10.4.0\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Getting Dataset Ready","metadata":{}},{"cell_type":"code","source":"class AeroHeliDataset(Dataset):\n    def __init__(self, root_dir, train=True, train_transform=None, test_transform=None):\n        \"\"\"\n        Args:\n            root_dir (string): Path to the dataset directory.\n            train (bool): If True, loads the training data. If False, loads the test data.\n            train_transform (callable, optional): Transformations for training data.\n            test_transform (callable, optional): Transformations for test data.\n        \"\"\"\n        self.root_dir = root_dir\n        self.train = train\n        self.train_transform = train_transform\n        self.test_transform = test_transform\n        \n        # The list of images and labels\n        self.images = []\n        self.labels = []\n        \n        # Set directory based on whether this is training or testing data\n        data_type = 'train' if self.train else 'test'\n        \n        # Load images and labels\n        for label, class_name in enumerate(['aero', 'heli']):  # 0 for 'aero', 1 for 'heli'\n            class_dir = os.path.join(root_dir, data_type, class_name)\n            for filename in os.listdir(class_dir):\n                if filename.endswith(\".jpg\"):  \n                    self.images.append(os.path.join(class_dir, filename))\n                    self.labels.append(label)\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image_path = self.images[idx]\n        label = self.labels[idx]\n        \n        # Open the image\n        image = Image.open(image_path).convert(\"RGB\")\n        \n        # Apply appropriate transformations\n        if self.train and self.train_transform:\n            image = self.train_transform(image)\n        elif not self.train and self.test_transform:\n            image = self.test_transform(image)\n        \n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:02.766975Z","iopub.execute_input":"2024-11-13T18:39:02.767266Z","iopub.status.idle":"2024-11-13T18:39:02.777112Z","shell.execute_reply.started":"2024-11-13T18:39:02.767235Z","shell.execute_reply":"2024-11-13T18:39:02.776099Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Defining different transforms for different models\n\nbasic_transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resizing images to 224x224\n    transforms.ToTensor()\n])\n\naugmented_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    # Augmentation\n    transforms.RandomHorizontalFlip(),  \n    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n    transforms.ToTensor(),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:02.778449Z","iopub.execute_input":"2024-11-13T18:39:02.778871Z","iopub.status.idle":"2024-11-13T18:39:02.789122Z","shell.execute_reply.started":"2024-11-13T18:39:02.778827Z","shell.execute_reply":"2024-11-13T18:39:02.788215Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"root_dir = \"/kaggle/input/aeroplane-helicopter-image-classification/dataset_aero_heli\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:02.790383Z","iopub.execute_input":"2024-11-13T18:39:02.790756Z","iopub.status.idle":"2024-11-13T18:39:02.802232Z","shell.execute_reply.started":"2024-11-13T18:39:02.790711Z","shell.execute_reply":"2024-11-13T18:39:02.801415Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Training datasets for each type\ntrain_dataset_basic = AeroHeliDataset(root_dir=root_dir, train=True, train_transform=basic_transform)\n\nonly_augmented_1 = AeroHeliDataset(root_dir=root_dir, train=True, train_transform=augmented_transform)\nonly_augmented_2 = AeroHeliDataset(root_dir=root_dir, train=True, train_transform=augmented_transform)\ntrain_dataset_augmented = ConcatDataset([train_dataset_basic, only_augmented_1, only_augmented_2]) # Concatinating extra augments\n\n# Corresponding test datasets for each type (without augmentation)\ntest_dataset_basic = AeroHeliDataset(root_dir=root_dir, train=False, test_transform=basic_transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:02.803287Z","iopub.execute_input":"2024-11-13T18:39:02.803602Z","iopub.status.idle":"2024-11-13T18:39:02.885057Z","shell.execute_reply.started":"2024-11-13T18:39:02.803571Z","shell.execute_reply":"2024-11-13T18:39:02.884370Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:02.886006Z","iopub.execute_input":"2024-11-13T18:39:02.886295Z","iopub.status.idle":"2024-11-13T18:39:02.943788Z","shell.execute_reply.started":"2024-11-13T18:39:02.886263Z","shell.execute_reply":"2024-11-13T18:39:02.942752Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Defining Different Models","metadata":{}},{"cell_type":"code","source":"# 1 Block model\n\nclass Model1Block(nn.Module):\n    def __init__(self):\n        super(Model1Block, self).__init__()\n        # Block 1\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        # Fully connected layers\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(32 * 112 * 112, 128)\n        self.fc2 = nn.Linear(128, 1)\n        \n    def forward(self, x):\n        # Block 1\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        # Flatten\n        x = self.flatten(x)\n        # Fully connected layers\n        x = F.relu(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))\n        \n        return x\n\nsummary(Model1Block().to(device), input_size=(3, 224, 224))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:02.948134Z","iopub.execute_input":"2024-11-13T18:39:02.948450Z","iopub.status.idle":"2024-11-13T18:39:04.490916Z","shell.execute_reply.started":"2024-11-13T18:39:02.948408Z","shell.execute_reply":"2024-11-13T18:39:04.489966Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 32, 224, 224]             896\n         MaxPool2d-2         [-1, 32, 112, 112]               0\n           Flatten-3               [-1, 401408]               0\n            Linear-4                  [-1, 128]      51,380,352\n            Linear-5                    [-1, 1]             129\n================================================================\nTotal params: 51,381,377\nTrainable params: 51,381,377\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 18.38\nParams size (MB): 196.00\nEstimated Total Size (MB): 214.95\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":" # 3 Block model\n\nclass Model3Block(nn.Module):\n    def __init__(self):\n        super(Model3Block, self).__init__()\n        # Block 1\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        # Block 2\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        # Block 3\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)        \n        # Fully connected layers\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 28 * 28, 128)  # 128 channels * 28x28 (after 3 poolings)\n        self.fc2 = nn.Linear(128, 1)\n        \n    def forward(self, x):\n        # Block 1\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        # Block 2\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        # Block 3\n        x = F.relu(self.conv3(x))\n        x = self.pool(x)\n        # Flatten\n        x = self.flatten(x)\n        # Fully connected layers\n        x = F.relu(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))\n        \n        return x\n        \nsummary(Model3Block().to(device), input_size=(3, 224, 224))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:04.491936Z","iopub.execute_input":"2024-11-13T18:39:04.492234Z","iopub.status.idle":"2024-11-13T18:39:04.640749Z","shell.execute_reply.started":"2024-11-13T18:39:04.492202Z","shell.execute_reply":"2024-11-13T18:39:04.639747Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 32, 224, 224]             896\n         MaxPool2d-2         [-1, 32, 112, 112]               0\n            Conv2d-3         [-1, 64, 112, 112]          18,496\n         MaxPool2d-4           [-1, 64, 56, 56]               0\n            Conv2d-5          [-1, 128, 56, 56]          73,856\n         MaxPool2d-6          [-1, 128, 28, 28]               0\n           Flatten-7               [-1, 100352]               0\n            Linear-8                  [-1, 128]      12,845,184\n            Linear-9                    [-1, 1]             129\n================================================================\nTotal params: 12,938,561\nTrainable params: 12,938,561\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 27.56\nParams size (MB): 49.36\nEstimated Total Size (MB): 77.49\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Transfer learning using VGG16  with tuning all layers (including tuning convolution layers)\n\nclass VGGModel(nn.Module):\n    def __init__(self):\n        super(VGGModel, self).__init__()\n        # Load VGG16 model with pretrained weights, including the classifier (fully connected) layers\n        self.vgg16 = models.vgg16(weights='VGG16_Weights.DEFAULT')\n        \n        # Freeze all convolutional (feature extraction) layers, making them non-trainable\n        for param in self.vgg16.features.parameters():\n            param.requires_grad = True\n        \n        # Modify the final fully connected layer in the classifier for binary classification\n        num_features = self.vgg16.classifier[-1].in_features  # Get input features of the last layer\n        self.vgg16.classifier[-1] = nn.Linear(num_features, 1)  # Replace with a layer that outputs 1 value\n        \n    def forward(self, x):\n        # Forward pass through the entire model, including modified classifier\n        x = self.vgg16(x)\n        x = torch.sigmoid(x)  # Apply sigmoid to get probabilities for binary classification\n        return x\n\nsummary(VGGModel().to(device), input_size=(3, 224, 224))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:04.642212Z","iopub.execute_input":"2024-11-13T18:39:04.642565Z","iopub.status.idle":"2024-11-13T18:39:09.094183Z","shell.execute_reply.started":"2024-11-13T18:39:04.642524Z","shell.execute_reply":"2024-11-13T18:39:09.093230Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 216MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 224, 224]           1,792\n              ReLU-2         [-1, 64, 224, 224]               0\n            Conv2d-3         [-1, 64, 224, 224]          36,928\n              ReLU-4         [-1, 64, 224, 224]               0\n         MaxPool2d-5         [-1, 64, 112, 112]               0\n            Conv2d-6        [-1, 128, 112, 112]          73,856\n              ReLU-7        [-1, 128, 112, 112]               0\n            Conv2d-8        [-1, 128, 112, 112]         147,584\n              ReLU-9        [-1, 128, 112, 112]               0\n        MaxPool2d-10          [-1, 128, 56, 56]               0\n           Conv2d-11          [-1, 256, 56, 56]         295,168\n             ReLU-12          [-1, 256, 56, 56]               0\n           Conv2d-13          [-1, 256, 56, 56]         590,080\n             ReLU-14          [-1, 256, 56, 56]               0\n           Conv2d-15          [-1, 256, 56, 56]         590,080\n             ReLU-16          [-1, 256, 56, 56]               0\n        MaxPool2d-17          [-1, 256, 28, 28]               0\n           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n             ReLU-19          [-1, 512, 28, 28]               0\n           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n             ReLU-21          [-1, 512, 28, 28]               0\n           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n             ReLU-23          [-1, 512, 28, 28]               0\n        MaxPool2d-24          [-1, 512, 14, 14]               0\n           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n             ReLU-26          [-1, 512, 14, 14]               0\n           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n             ReLU-28          [-1, 512, 14, 14]               0\n           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n             ReLU-30          [-1, 512, 14, 14]               0\n        MaxPool2d-31            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n           Linear-33                 [-1, 4096]     102,764,544\n             ReLU-34                 [-1, 4096]               0\n          Dropout-35                 [-1, 4096]               0\n           Linear-36                 [-1, 4096]      16,781,312\n             ReLU-37                 [-1, 4096]               0\n          Dropout-38                 [-1, 4096]               0\n           Linear-39                    [-1, 1]           4,097\n              VGG-40                    [-1, 1]               0\n================================================================\nTotal params: 134,264,641\nTrainable params: 134,264,641\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 218.77\nParams size (MB): 512.18\nEstimated Total Size (MB): 731.53\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Transfer learning using VGG16 or VGG19 with tuning only final MLP layers (excluding convolution layers)\n\nclass VGGModel_1(nn.Module):\n    def __init__(self):\n        super(VGGModel_1, self).__init__()\n        # Load VGG16 model with pretrained weights, including the classifier (fully connected) layers\n        self.vgg16 = models.vgg16(weights='VGG16_Weights.DEFAULT')\n        \n        # Freeze all convolutional (feature extraction) layers, making them non-trainable\n        for param in self.vgg16.features.parameters():\n            param.requires_grad = False\n        \n        # Modify the final fully connected layer in the classifier for binary classification\n        num_features = self.vgg16.classifier[-1].in_features  # Get input features of the last layer\n        self.vgg16.classifier[-1] = nn.Linear(num_features, 1)  # Replace with a layer that outputs 1 value\n        \n    def forward(self, x):\n        # Forward pass through the entire model, including modified classifier\n        x = self.vgg16(x)\n        x = torch.sigmoid(x)  # Apply sigmoid to get probabilities for binary classification\n        return x\n        \nsummary(VGGModel_1().to(device), [(3, 224, 224)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:09.095587Z","iopub.execute_input":"2024-11-13T18:39:09.096346Z","iopub.status.idle":"2024-11-13T18:39:10.741771Z","shell.execute_reply.started":"2024-11-13T18:39:09.096296Z","shell.execute_reply":"2024-11-13T18:39:10.740918Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 224, 224]           1,792\n              ReLU-2         [-1, 64, 224, 224]               0\n            Conv2d-3         [-1, 64, 224, 224]          36,928\n              ReLU-4         [-1, 64, 224, 224]               0\n         MaxPool2d-5         [-1, 64, 112, 112]               0\n            Conv2d-6        [-1, 128, 112, 112]          73,856\n              ReLU-7        [-1, 128, 112, 112]               0\n            Conv2d-8        [-1, 128, 112, 112]         147,584\n              ReLU-9        [-1, 128, 112, 112]               0\n        MaxPool2d-10          [-1, 128, 56, 56]               0\n           Conv2d-11          [-1, 256, 56, 56]         295,168\n             ReLU-12          [-1, 256, 56, 56]               0\n           Conv2d-13          [-1, 256, 56, 56]         590,080\n             ReLU-14          [-1, 256, 56, 56]               0\n           Conv2d-15          [-1, 256, 56, 56]         590,080\n             ReLU-16          [-1, 256, 56, 56]               0\n        MaxPool2d-17          [-1, 256, 28, 28]               0\n           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n             ReLU-19          [-1, 512, 28, 28]               0\n           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n             ReLU-21          [-1, 512, 28, 28]               0\n           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n             ReLU-23          [-1, 512, 28, 28]               0\n        MaxPool2d-24          [-1, 512, 14, 14]               0\n           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n             ReLU-26          [-1, 512, 14, 14]               0\n           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n             ReLU-28          [-1, 512, 14, 14]               0\n           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n             ReLU-30          [-1, 512, 14, 14]               0\n        MaxPool2d-31            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n           Linear-33                 [-1, 4096]     102,764,544\n             ReLU-34                 [-1, 4096]               0\n          Dropout-35                 [-1, 4096]               0\n           Linear-36                 [-1, 4096]      16,781,312\n             ReLU-37                 [-1, 4096]               0\n          Dropout-38                 [-1, 4096]               0\n           Linear-39                    [-1, 1]           4,097\n              VGG-40                    [-1, 1]               0\n================================================================\nTotal params: 134,264,641\nTrainable params: 119,549,953\nNon-trainable params: 14,714,688\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 218.77\nParams size (MB): 512.18\nEstimated Total Size (MB): 731.53\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def get_model(model_name):\n    if model_name == \"1_block\":\n        model = Model1Block()\n    elif model_name == \"3_block\":\n        model = Model3Block()\n    elif model_name == \"3_block_aug\":\n        model = Model3Block()\n    elif model_name == \"vgg_16\":\n        model = VGGModel()\n    elif model_name == \"vgg_16_1\":\n        model = VGGModel_1()\n    else:\n        raise ValueError(f\"Model {model_name} is not defined\")\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:10.743270Z","iopub.execute_input":"2024-11-13T18:39:10.743587Z","iopub.status.idle":"2024-11-13T18:39:10.749192Z","shell.execute_reply.started":"2024-11-13T18:39:10.743554Z","shell.execute_reply":"2024-11-13T18:39:10.747986Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Training and Evaluation","metadata":{}},{"cell_type":"code","source":"# Hyperparameters\nnum_epochs = 10\nbatch_size = 16\nlearning_rate = 1e-4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:10.750522Z","iopub.execute_input":"2024-11-13T18:39:10.751384Z","iopub.status.idle":"2024-11-13T18:39:10.758364Z","shell.execute_reply.started":"2024-11-13T18:39:10.751340Z","shell.execute_reply":"2024-11-13T18:39:10.757636Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def log_images_with_predictions(data, targets, predictions, writer, step):\n    true_labels = targets.squeeze().tolist()\n    pred_labels = predictions.squeeze().tolist()\n\n    # Set up the plot grid for 16 images (since batch size is 16)\n    fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(16, 12))  \n    axes = axes.flatten()\n\n    for img, true_label, pred_label, ax in zip(data[:16], true_labels[:16], pred_labels[:16], axes):\n        img = img.permute(1, 2, 0).cpu().numpy()\n\n        # Plot the image\n        ax.imshow(img)\n        ax.axis('off')\n\n        # Set title with true/pred labels\n        title_color = \"green\" if true_label == pred_label else \"red\"\n        ax.set_title(f\"True: {int(true_label)} | Pred: {int(pred_label)}\", color=title_color)\n\n    # Save the plot to a temporary file\n    plt.tight_layout()\n    plt_path = \"temp_plot_final_epoch.jpg\"\n    plt.savefig(plt_path, bbox_inches='tight', format='jpg')\n    plt.close(fig)\n    \n    pil_img = Image.open(plt_path)\n    pil_img = pil_img.convert(\"RGB\")\n    img_np = np.array(pil_img)\n\n    # Log the image to TensorBoard\n    writer.add_image(\"Test Images with Predictions\", img_np.transpose(2, 0, 1), global_step=step)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:10.759737Z","iopub.execute_input":"2024-11-13T18:39:10.760149Z","iopub.status.idle":"2024-11-13T18:39:10.770299Z","shell.execute_reply.started":"2024-11-13T18:39:10.760108Z","shell.execute_reply":"2024-11-13T18:39:10.769390Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def train_and_evaluate(model_name, train_dataset, test_dataset,num_epochs = 10, batch_size = 16, learning_rate = 1e-4):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Initialize model\n    model = get_model(model_name)\n    model.to(device)\n\n    # Define loss and optimizer\n    criterion = nn.BCELoss()  \n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    \n    # Data loaders\n    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n    # TensorBoard writers\n    writer_train = SummaryWriter(f\"runs/{model_name}_Train\")\n    writer_test = SummaryWriter(f\"runs/{model_name}_Test\")\n\n    # Log model graph for first iteration\n    images, _ = next(iter(train_loader))\n    writer_train.add_graph(model, images.to(device))\n    \n    step_train, step_test = 0, 0\n    total_training_time = 0\n\n    # Initialize lists to accumulate losses and accuracies\n    train_losses = []\n    train_accuracies = []\n    test_accuracies = []\n\n    model_dir = \"/kaggle/working/saved_models\"\n    os.makedirs(model_dir, exist_ok=True)\n\n    # Training and evaluation loop\n    for epoch in range(num_epochs):\n        # Training phase\n        start_time = time.time()\n        model.train()\n        for batch_idx, (data, targets) in enumerate(train_loader):\n            data = torch.tensor(data, dtype=torch.float32).to(device)\n            targets = torch.tensor(targets, dtype=torch.float32).unsqueeze(1).to(device)\n            \n            # Forward pass\n            scores = model(data)\n            loss = criterion(scores, targets)\n            train_losses.append(loss.item())\n            \n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Calculate training accuracy\n            predictions = (scores > 0.5).float()  \n            correct = (predictions == targets).sum().item()\n            accuracy = correct / data.shape[0]\n            train_accuracies.append(accuracy)\n\n            # Log to TensorBoard for training\n            writer_train.add_scalar(\"Loss\", loss.item(), global_step=step_train)\n            writer_train.add_scalar(\"Accuracy\", accuracy, global_step=step_train)\n            \n            step_train += 1\n\n        # End timing the training phase\n        end_time = time.time()\n        total_training_time += end_time - start_time\n        \n        # Test phase (no gradients needed)\n        model.eval()\n        with torch.no_grad():\n            for data, targets in test_loader:\n                data = torch.tensor(data, dtype=torch.float32).to(device)\n                targets = torch.tensor(targets, dtype=torch.float32).unsqueeze(1).to(device)\n                \n                # Forward pass\n                scores = model(data)\n                loss = criterion(scores, targets)\n\n                # Calculate test accuracy\n                predictions = (scores > 0.5).float() \n                correct = (predictions == targets).sum().item()\n                accuracy = correct / data.shape[0]\n                test_accuracies.append(accuracy)\n\n                # Log to TensorBoard for testing\n                writer_test.add_scalar(\"Accuracy\", accuracy, global_step=step_test)\n                \n                # Accumulate final predictions to visualize\n                if epoch == num_epochs - 1:\n                    log_images_with_predictions(data, targets, predictions, writer_test, step_test)\n                \n                step_test += 1\n                \n        # Calculate and print the epoch metrics\n        avg_train_loss = sum(train_losses) / len(train_losses)\n        avg_train_acc = sum(train_accuracies) / len(train_accuracies)\n        avg_test_acc = sum(test_accuracies) / len(test_accuracies)\n\n        print(f\"\\nEpoch [{epoch+1}/{num_epochs}] - \"\n              f\"Train Loss: {avg_train_loss:.4f}, \"\n              f\"Train Accuracy: {avg_train_acc:.4f}, \"\n              f\"Test Accuracy: {avg_test_acc:.4f}, \")\n\n    # Save final model\n    torch.save(model.state_dict(), os.path.join(model_dir, f\"{model_name}_final.pth\"))\n    \n    print(f\"\\n------------\\nTotal Training Time: {total_training_time:.4f} seconds \\n-------------\\n\")  \n    print(f\"\\n------------\\nPer Epoch Training Time: {(total_training_time / num_epochs):.4f} seconds per epoch \\n-------------\\n\")\n    \n    # Close the writers\n    writer_train.close()\n    writer_test.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:10.771693Z","iopub.execute_input":"2024-11-13T18:39:10.771966Z","iopub.status.idle":"2024-11-13T18:39:10.791261Z","shell.execute_reply.started":"2024-11-13T18:39:10.771936Z","shell.execute_reply":"2024-11-13T18:39:10.790449Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"train_and_evaluate(model_name=\"1_block\", train_dataset=train_dataset_basic, test_dataset=test_dataset_basic)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:39:10.792337Z","iopub.execute_input":"2024-11-13T18:39:10.792703Z","iopub.status.idle":"2024-11-13T18:41:29.046052Z","shell.execute_reply.started":"2024-11-13T18:39:10.792658Z","shell.execute_reply":"2024-11-13T18:41:29.045140Z"}},"outputs":[{"name":"stdout","text":"\nEpoch [1/10] - Train Loss: 0.8571, Train Accuracy: 0.5813, Test Accuracy: 0.8750, \n\nEpoch [2/10] - Train Loss: 0.5695, Train Accuracy: 0.7250, Test Accuracy: 0.8542, \n\nEpoch [3/10] - Train Loss: 0.4488, Train Accuracy: 0.7812, Test Accuracy: 0.8750, \n\nEpoch [4/10] - Train Loss: 0.3729, Train Accuracy: 0.8172, Test Accuracy: 0.8802, \n\nEpoch [5/10] - Train Loss: 0.3177, Train Accuracy: 0.8512, Test Accuracy: 0.8917, \n\nEpoch [6/10] - Train Loss: 0.2812, Train Accuracy: 0.8729, Test Accuracy: 0.8958, \n\nEpoch [7/10] - Train Loss: 0.2539, Train Accuracy: 0.8893, Test Accuracy: 0.9048, \n\nEpoch [8/10] - Train Loss: 0.2288, Train Accuracy: 0.9008, Test Accuracy: 0.8984, \n\nEpoch [9/10] - Train Loss: 0.2084, Train Accuracy: 0.9111, Test Accuracy: 0.9005, \n\nEpoch [10/10] - Train Loss: 0.1904, Train Accuracy: 0.9194, Test Accuracy: 0.9042, \n\n------------\nTotal Training Time: 89.6671 seconds \n-------------\n\n\n------------\nPer Epoch Training Time: 8.9667 seconds per epoch \n-------------\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"train_and_evaluate(model_name=\"3_block\", train_dataset=train_dataset_basic, test_dataset=test_dataset_basic)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:41:29.047333Z","iopub.execute_input":"2024-11-13T18:41:29.047666Z","iopub.status.idle":"2024-11-13T18:43:43.925463Z","shell.execute_reply.started":"2024-11-13T18:41:29.047632Z","shell.execute_reply":"2024-11-13T18:43:43.924409Z"}},"outputs":[{"name":"stdout","text":"\nEpoch [1/10] - Train Loss: 0.6801, Train Accuracy: 0.5563, Test Accuracy: 0.7500, \n\nEpoch [2/10] - Train Loss: 0.5906, Train Accuracy: 0.7000, Test Accuracy: 0.7917, \n\nEpoch [3/10] - Train Loss: 0.5242, Train Accuracy: 0.7396, Test Accuracy: 0.7986, \n\nEpoch [4/10] - Train Loss: 0.4788, Train Accuracy: 0.7734, Test Accuracy: 0.8073, \n\nEpoch [5/10] - Train Loss: 0.4398, Train Accuracy: 0.7925, Test Accuracy: 0.8250, \n\nEpoch [6/10] - Train Loss: 0.4042, Train Accuracy: 0.8156, Test Accuracy: 0.8368, \n\nEpoch [7/10] - Train Loss: 0.3729, Train Accuracy: 0.8330, Test Accuracy: 0.8482, \n\nEpoch [8/10] - Train Loss: 0.3428, Train Accuracy: 0.8500, Test Accuracy: 0.8542, \n\nEpoch [9/10] - Train Loss: 0.3149, Train Accuracy: 0.8653, Test Accuracy: 0.8634, \n\nEpoch [10/10] - Train Loss: 0.2911, Train Accuracy: 0.8775, Test Accuracy: 0.8729, \n\n------------\nTotal Training Time: 88.6417 seconds \n-------------\n\n\n------------\nPer Epoch Training Time: 8.8642 seconds per epoch \n-------------\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"train_and_evaluate(model_name=\"3_block_aug\", train_dataset=train_dataset_augmented, test_dataset=test_dataset_basic)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:43:43.926990Z","iopub.execute_input":"2024-11-13T18:43:43.927765Z","iopub.status.idle":"2024-11-13T18:49:15.357368Z","shell.execute_reply.started":"2024-11-13T18:43:43.927711Z","shell.execute_reply":"2024-11-13T18:49:15.356398Z"}},"outputs":[{"name":"stdout","text":"\nEpoch [1/10] - Train Loss: 0.5962, Train Accuracy: 0.6792, Test Accuracy: 0.7917, \n\nEpoch [2/10] - Train Loss: 0.4877, Train Accuracy: 0.7531, Test Accuracy: 0.8646, \n\nEpoch [3/10] - Train Loss: 0.3870, Train Accuracy: 0.8146, Test Accuracy: 0.8889, \n\nEpoch [4/10] - Train Loss: 0.3164, Train Accuracy: 0.8536, Test Accuracy: 0.9062, \n\nEpoch [5/10] - Train Loss: 0.2662, Train Accuracy: 0.8796, Test Accuracy: 0.9167, \n\nEpoch [6/10] - Train Loss: 0.2270, Train Accuracy: 0.8990, Test Accuracy: 0.9236, \n\nEpoch [7/10] - Train Loss: 0.1979, Train Accuracy: 0.9131, Test Accuracy: 0.9286, \n\nEpoch [8/10] - Train Loss: 0.1757, Train Accuracy: 0.9232, Test Accuracy: 0.9323, \n\nEpoch [9/10] - Train Loss: 0.1578, Train Accuracy: 0.9317, Test Accuracy: 0.9352, \n\nEpoch [10/10] - Train Loss: 0.1427, Train Accuracy: 0.9385, Test Accuracy: 0.9375, \n\n------------\nTotal Training Time: 282.8568 seconds \n-------------\n\n\n------------\nPer Epoch Training Time: 28.2857 seconds per epoch \n-------------\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"train_and_evaluate(model_name=\"vgg_16\", train_dataset=train_dataset_basic, test_dataset=test_dataset_basic, num_epochs = 5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:49:15.358960Z","iopub.execute_input":"2024-11-13T18:49:15.359654Z","iopub.status.idle":"2024-11-13T18:50:41.404223Z","shell.execute_reply.started":"2024-11-13T18:49:15.359601Z","shell.execute_reply":"2024-11-13T18:50:41.403213Z"}},"outputs":[{"name":"stdout","text":"\nEpoch [1/5] - Train Loss: 0.2057, Train Accuracy: 0.9000, Test Accuracy: 0.9792, \n\nEpoch [2/5] - Train Loss: 0.1434, Train Accuracy: 0.9437, Test Accuracy: 0.9583, \n\nEpoch [3/5] - Train Loss: 0.1669, Train Accuracy: 0.9583, Test Accuracy: 0.9444, \n\nEpoch [4/5] - Train Loss: 0.1298, Train Accuracy: 0.9672, Test Accuracy: 0.9583, \n\nEpoch [5/5] - Train Loss: 0.1039, Train Accuracy: 0.9738, Test Accuracy: 0.9667, \n\n------------\nTotal Training Time: 54.7540 seconds \n-------------\n\n\n------------\nPer Epoch Training Time: 10.9508 seconds per epoch \n-------------\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"train_and_evaluate(model_name=\"vgg_16_1\", train_dataset=train_dataset_basic, test_dataset=test_dataset_basic, num_epochs =  5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:50:41.405736Z","iopub.execute_input":"2024-11-13T18:50:41.406093Z","iopub.status.idle":"2024-11-13T18:51:59.617606Z","shell.execute_reply.started":"2024-11-13T18:50:41.406057Z","shell.execute_reply":"2024-11-13T18:51:59.616586Z"}},"outputs":[{"name":"stdout","text":"\nEpoch [1/5] - Train Loss: 0.2532, Train Accuracy: 0.8750, Test Accuracy: 0.9792, \n\nEpoch [2/5] - Train Loss: 0.1288, Train Accuracy: 0.9375, Test Accuracy: 0.9792, \n\nEpoch [3/5] - Train Loss: 0.0860, Train Accuracy: 0.9583, Test Accuracy: 0.9792, \n\nEpoch [4/5] - Train Loss: 0.0645, Train Accuracy: 0.9688, Test Accuracy: 0.9792, \n\nEpoch [5/5] - Train Loss: 0.0516, Train Accuracy: 0.9750, Test Accuracy: 0.9792, \n\n------------\nTotal Training Time: 47.5793 seconds \n-------------\n\n\n------------\nPer Epoch Training Time: 9.5159 seconds per epoch \n-------------\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!zip -r runs.zip runs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:51:59.619151Z","iopub.execute_input":"2024-11-13T18:51:59.619593Z","iopub.status.idle":"2024-11-13T18:52:01.254756Z","shell.execute_reply.started":"2024-11-13T18:51:59.619546Z","shell.execute_reply":"2024-11-13T18:52:01.253495Z"}},"outputs":[{"name":"stdout","text":"  adding: runs/ (stored 0%)\n  adding: runs/vgg_16_1_Train/ (stored 0%)\n  adding: runs/vgg_16_1_Train/events.out.tfevents.1731523842.c6d0534cfc01.30.8 (deflated 90%)\n  adding: runs/1_block_Test/ (stored 0%)\n  adding: runs/1_block_Test/events.out.tfevents.1731523151.c6d0534cfc01.30.1 (deflated 0%)\n  adding: runs/3_block_Train/ (stored 0%)\n  adding: runs/3_block_Train/events.out.tfevents.1731523289.c6d0534cfc01.30.2 (deflated 77%)\n  adding: runs/3_block_aug_Train/ (stored 0%)\n  adding: runs/3_block_aug_Train/events.out.tfevents.1731523424.c6d0534cfc01.30.4 (deflated 73%)\n  adding: runs/vgg_16_1_Test/ (stored 0%)\n  adding: runs/vgg_16_1_Test/events.out.tfevents.1731523842.c6d0534cfc01.30.9 (deflated 0%)\n  adding: runs/3_block_aug_Test/ (stored 0%)\n  adding: runs/3_block_aug_Test/events.out.tfevents.1731523424.c6d0534cfc01.30.5 (deflated 0%)\n  adding: runs/vgg_16_Train/ (stored 0%)\n  adding: runs/vgg_16_Train/events.out.tfevents.1731523756.c6d0534cfc01.30.6 (deflated 90%)\n  adding: runs/1_block_Train/ (stored 0%)\n  adding: runs/1_block_Train/events.out.tfevents.1731523151.c6d0534cfc01.30.0 (deflated 70%)\n  adding: runs/vgg_16_Test/ (stored 0%)\n  adding: runs/vgg_16_Test/events.out.tfevents.1731523756.c6d0534cfc01.30.7 (deflated 0%)\n  adding: runs/3_block_Test/ (stored 0%)\n  adding: runs/3_block_Test/events.out.tfevents.1731523289.c6d0534cfc01.30.3 (deflated 0%)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!zip -r saved_models.zip saved_models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:52:01.256482Z","iopub.execute_input":"2024-11-13T18:52:01.256835Z","iopub.status.idle":"2024-11-13T18:53:15.044829Z","shell.execute_reply.started":"2024-11-13T18:52:01.256799Z","shell.execute_reply":"2024-11-13T18:53:15.043807Z"}},"outputs":[{"name":"stdout","text":"  adding: saved_models/ (stored 0%)\n  adding: saved_models/3_block_final.pth (deflated 8%)\n  adding: saved_models/1_block_final.pth (deflated 8%)\n  adding: saved_models/3_block_aug_final.pth (deflated 7%)\n  adding: saved_models/vgg_16_final.pth (deflated 7%)\n  adding: saved_models/vgg_16_1_final.pth (deflated 7%)\n","output_type":"stream"}],"execution_count":24}]}